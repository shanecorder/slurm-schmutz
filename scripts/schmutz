#!/usr/bin/env python3
"""
Schmutz - Slurm Job Efficiency Monitor for Open OnDemand

A standalone CLI utility for displaying Slurm job efficiency metrics,
inspired by jobstats and jobperf from Clemson University.

This is a self-contained script with no external dependencies beyond
Python 3.7+ standard library. PyYAML is optional for config file support.

Usage:
    schmutz <job_id>           Show efficiency for a job
    schmutz status <job_id>    Same as above
    schmutz update <job_id>    Update OOD session card for job
    schmutz list               List active OOD sessions
    schmutz html <job_id>      Generate HTML card output

Drop this file into a shared location (e.g., /opt/slurm/bin/schmutz),
make it executable (chmod +x), and all users can run it.
"""

import sys

# Version check - must be before other imports that require 3.7+
if sys.version_info < (3, 7):
    sys.exit(
        f"Error: schmutz requires Python 3.7 or later.\n"
        f"You are running Python {sys.version_info.major}.{sys.version_info.minor}.\n"
        f"Try: module load python/3.8 (or similar) before running schmutz."
    )

__version__ = "1.0.1"

import argparse
import json
import logging
import os
import pwd
import re
import subprocess
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# Try to import yaml, but make it optional
try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False

logger = logging.getLogger(__name__)


# =============================================================================
# Configuration Classes
# =============================================================================

@dataclass
class EfficiencyThresholds:
    """Thresholds for color-coded efficiency indicators."""
    cpu_good: float = 80.0
    cpu_warning: float = 50.0
    memory_good: float = 70.0
    memory_warning: float = 40.0
    gpu_good: float = 70.0
    gpu_warning: float = 40.0
    gpu_memory_good: float = 50.0
    gpu_memory_warning: float = 25.0


def _find_command(name: str) -> str:
    """Find command path, checking common locations."""
    import shutil
    
    # Common Slurm installation paths (checked in order)
    common_paths = [
        '/usr/bin',
        '/usr/local/bin', 
        '/opt/slurm/bin',
        '/cm/shared/apps/slurm/current/bin',
        '/cm/local/apps/slurm/current/bin',
        '/apps/slurm/bin',
        '/usr/local/slurm/bin',
        '/opt/ohpc/pub/slurm/bin',
    ]
    
    # Check common locations first (more reliable than user's potentially modified PATH)
    for prefix in common_paths:
        candidate = os.path.join(prefix, name)
        if os.path.isfile(candidate) and os.access(candidate, os.X_OK):
            return candidate
    
    # Try to find in PATH as fallback
    path = shutil.which(name)
    if path:
        return path
    
    # Last resort: return the bare command name and hope it's in PATH at runtime
    return name


@dataclass
class SlurmConfig:
    """Slurm-related configuration."""
    sstat_path: str = field(default_factory=lambda: _find_command('sstat'))
    sacct_path: str = field(default_factory=lambda: _find_command('sacct'))
    squeue_path: str = field(default_factory=lambda: _find_command('squeue'))
    scontrol_path: str = field(default_factory=lambda: _find_command('scontrol'))
    command_timeout: int = 30
    
    def __post_init__(self):
        """Ensure all paths are valid strings, not None."""
        if not self.sstat_path:
            self.sstat_path = _find_command('sstat')
        if not self.sacct_path:
            self.sacct_path = _find_command('sacct')
        if not self.squeue_path:
            self.squeue_path = _find_command('squeue')
        if not self.scontrol_path:
            self.scontrol_path = _find_command('scontrol')


@dataclass
class Config:
    """Main configuration class for Schmutz."""
    ood_data_root: str = "/var/lib/ondemand-nginx"
    session_data_dir: str = "data/sys/dashboard/batch_connect/db"
    log_level: str = "INFO"
    log_file: Optional[str] = None
    thresholds: EfficiencyThresholds = field(default_factory=EfficiencyThresholds)
    slurm: SlurmConfig = field(default_factory=SlurmConfig)
    card_title: str = "Job Efficiency"
    show_recommendations: bool = True
    compact_mode: bool = False

    @classmethod
    def from_yaml(cls, config_path: str) -> "Config":
        """Load configuration from a YAML file."""
        if not HAS_YAML:
            logger.warning("PyYAML not installed, using default configuration")
            return cls()
        
        config_file = Path(config_path)
        if not config_file.exists():
            logger.warning(f"Config file not found: {config_path}, using defaults")
            return cls()

        try:
            with open(config_file, 'r') as f:
                data = yaml.safe_load(f) or {}
            return cls.from_dict(data)
        except Exception as e:
            logger.error(f"Error parsing config file: {e}")
            return cls()

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "Config":
        """Create configuration from a dictionary."""
        thresholds_data = data.pop('thresholds', {})
        slurm_data = data.pop('slurm', {})
        # Filter out None values to preserve defaults
        thresholds_data = {k: v for k, v in thresholds_data.items() if v is not None}
        slurm_data = {k: v for k, v in slurm_data.items() if v is not None}
        thresholds = EfficiencyThresholds(**thresholds_data) if thresholds_data else EfficiencyThresholds()
        slurm = SlurmConfig(**slurm_data) if slurm_data else SlurmConfig()
        return cls(
            thresholds=thresholds,
            slurm=slurm,
            **{k: v for k, v in data.items() if k in cls.__dataclass_fields__ and v is not None}
        )

    def get_user_session_path(self, username: str) -> Path:
        """Get the OOD session data path for a specific user."""
        return Path(self.ood_data_root) / username / self.session_data_dir


def get_default_config_paths() -> List[str]:
    """Return list of default configuration file paths to check."""
    return [
        "/etc/schmutz/config.yaml",
        "/etc/schmutz/config.yml",
        os.path.expanduser("~/.config/schmutz/config.yaml"),
        os.path.expanduser("~/.config/schmutz/config.yml"),
        "./config/config.yaml",
        "./config.yaml",
    ]


def load_config(config_path: Optional[str] = None) -> Config:
    """Load configuration from file or use defaults."""
    if config_path:
        return Config.from_yaml(config_path)
    for path in get_default_config_paths():
        if os.path.exists(path):
            logger.info(f"Loading config from: {path}")
            return Config.from_yaml(path)
    logger.debug("No config file found, using defaults")
    return Config()


# =============================================================================
# Job Statistics Classes
# =============================================================================

class JobState(Enum):
    """Slurm job states."""
    PENDING = "PENDING"
    RUNNING = "RUNNING"
    COMPLETED = "COMPLETED"
    FAILED = "FAILED"
    CANCELLED = "CANCELLED"
    TIMEOUT = "TIMEOUT"
    NODE_FAIL = "NODE_FAIL"
    PREEMPTED = "PREEMPTED"
    UNKNOWN = "UNKNOWN"

    @classmethod
    def from_string(cls, state_str: str) -> "JobState":
        """Convert Slurm state string to enum."""
        state_str = state_str.upper().split()[0]
        try:
            return cls(state_str)
        except ValueError:
            return cls.UNKNOWN

    @property
    def is_running(self) -> bool:
        return self == JobState.RUNNING

    @property
    def is_completed(self) -> bool:
        return self in (JobState.COMPLETED, JobState.FAILED, JobState.CANCELLED,
                       JobState.TIMEOUT, JobState.NODE_FAIL, JobState.PREEMPTED)

    @property
    def is_successful(self) -> bool:
        return self == JobState.COMPLETED


@dataclass
class GPUMetrics:
    """GPU utilization metrics."""
    gpu_id: int = 0
    gpu_name: str = ""
    utilization: float = 0.0
    memory_used: float = 0.0
    memory_total: float = 0.0
    memory_utilization: float = 0.0

    @property
    def memory_used_gb(self) -> float:
        return self.memory_used / (1024 ** 3)

    @property
    def memory_total_gb(self) -> float:
        return self.memory_total / (1024 ** 3)


@dataclass
class JobMetrics:
    """Complete job metrics including efficiency calculations."""
    job_id: str = ""
    job_name: str = ""
    user: str = ""
    state: JobState = JobState.UNKNOWN
    submit_time: Optional[datetime] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    elapsed_time: timedelta = field(default_factory=timedelta)
    time_limit: timedelta = field(default_factory=timedelta)
    num_nodes: int = 0
    num_cpus: int = 0
    num_gpus: int = 0
    memory_requested: float = 0.0
    partition: str = ""
    cpu_time_total: float = 0.0
    cpu_efficiency: float = 0.0
    memory_used_max: float = 0.0
    memory_used_avg: float = 0.0
    memory_efficiency: float = 0.0
    gpu_utilization_avg: float = 0.0
    gpu_memory_utilization_avg: float = 0.0
    gpu_metrics: List[GPUMetrics] = field(default_factory=list)
    last_updated: Optional[datetime] = None
    error_message: Optional[str] = None

    @property
    def elapsed_seconds(self) -> float:
        return self.elapsed_time.total_seconds()

    @property
    def time_limit_seconds(self) -> float:
        return self.time_limit.total_seconds()

    @property
    def time_efficiency(self) -> float:
        if self.time_limit_seconds <= 0:
            return 0.0
        return (self.elapsed_seconds / self.time_limit_seconds) * 100

    @property
    def memory_requested_gb(self) -> float:
        return self.memory_requested / (1024 ** 3)

    @property
    def memory_used_max_gb(self) -> float:
        return self.memory_used_max / (1024 ** 3)

    @property
    def has_gpus(self) -> bool:
        return self.num_gpus > 0

    def calculate_efficiency(self) -> None:
        """Calculate efficiency metrics from raw data."""
        if self.elapsed_seconds > 0 and self.num_cpus > 0:
            max_cpu_time = self.elapsed_seconds * self.num_cpus
            self.cpu_efficiency = (self.cpu_time_total / max_cpu_time) * 100
            self.cpu_efficiency = min(100.0, max(0.0, self.cpu_efficiency))
        if self.memory_requested > 0:
            self.memory_efficiency = (self.memory_used_max / self.memory_requested) * 100
            self.memory_efficiency = min(100.0, max(0.0, self.memory_efficiency))
        if self.gpu_metrics:
            self.gpu_utilization_avg = sum(g.utilization for g in self.gpu_metrics) / len(self.gpu_metrics)
            self.gpu_memory_utilization_avg = sum(g.memory_utilization for g in self.gpu_metrics) / len(self.gpu_metrics)


class JobStats:
    """Collects job statistics from Slurm."""

    def __init__(self, config: Optional[Config] = None):
        self.config = config or Config()
        self.slurm = self.config.slurm

    def _run_command(self, cmd: List[str], timeout: Optional[int] = None) -> Tuple[str, str, int]:
        """Run a shell command and return output."""
        timeout = timeout or self.slurm.command_timeout
        
        # Validate command list - convert all elements to strings and check for None
        try:
            cmd = [str(c) if c is not None else '' for c in cmd]
            if not cmd or not cmd[0]:
                logger.error("Empty or invalid command")
                return "", "Empty or invalid command", -1
        except (TypeError, ValueError) as e:
            logger.error(f"Invalid command format: {e}")
            return "", f"Invalid command format: {e}", -1
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)
            return result.stdout, result.stderr, result.returncode
        except subprocess.TimeoutExpired:
            logger.error(f"Command timed out: {' '.join(cmd)}")
            return "", "Command timed out", -1
        except FileNotFoundError:
            logger.error(f"Command not found: {cmd[0]}")
            return "", f"Command not found: {cmd[0]}", -1
        except Exception as e:
            logger.error(f"Error running command {' '.join(cmd)}: {e}")
            return "", str(e), -1

    def get_job_state(self, job_id: str) -> JobState:
        """Get the current state of a job."""
        cmd = [self.slurm.squeue_path, "-j", job_id, "--noheader", "-o", "%T"]
        stdout, stderr, rc = self._run_command(cmd)
        if rc == 0 and stdout.strip():
            return JobState.from_string(stdout.strip())
        cmd = [self.slurm.sacct_path, "-j", job_id, "--noheader", "-P", "-o", "State", "-n"]
        stdout, stderr, rc = self._run_command(cmd)
        if rc == 0 and stdout.strip():
            states = stdout.strip().split('\n')
            if states:
                return JobState.from_string(states[0])
        return JobState.UNKNOWN

    def _parse_memory(self, mem_str: str) -> float:
        """Parse Slurm memory string to bytes."""
        if not mem_str or mem_str == "":
            return 0.0
        mem_str = mem_str.strip().upper()
        multipliers = {'K': 1024, 'M': 1024 ** 2, 'G': 1024 ** 3, 'T': 1024 ** 4}
        match = re.match(r'^([\d.]+)([KMGT]?)$', mem_str)
        if match:
            value = float(match.group(1))
            suffix = match.group(2)
            return value * multipliers.get(suffix, 1)
        try:
            return float(mem_str)
        except ValueError:
            logger.warning(f"Could not parse memory value: {mem_str}")
            return 0.0

    def _parse_time(self, time_str: str) -> timedelta:
        """Parse Slurm time string to timedelta."""
        if not time_str or time_str == "":
            return timedelta()
        time_str = time_str.strip()
        days = 0
        if '-' in time_str:
            days_part, time_str = time_str.split('-', 1)
            days = int(days_part)
        parts = time_str.split(':')
        try:
            if len(parts) == 3:
                hours, minutes, seconds = map(float, parts)
            elif len(parts) == 2:
                hours = 0
                minutes, seconds = map(float, parts)
            elif len(parts) == 1:
                hours = 0
                minutes = 0
                seconds = float(parts[0])
            else:
                return timedelta()
            return timedelta(days=days, hours=hours, minutes=minutes, seconds=seconds)
        except ValueError:
            logger.warning(f"Could not parse time value: {time_str}")
            return timedelta()

    def _parse_datetime(self, dt_str: str) -> Optional[datetime]:
        """Parse Slurm datetime string."""
        if not dt_str or dt_str in ("Unknown", "None", "N/A"):
            return None
        formats = ["%Y-%m-%dT%H:%M:%S", "%Y-%m-%d %H:%M:%S", "%Y-%m-%dT%H:%M:%S.%f"]
        for fmt in formats:
            try:
                return datetime.strptime(dt_str.strip(), fmt)
            except ValueError:
                continue
        logger.warning(f"Could not parse datetime: {dt_str}")
        return None

    def _parse_cpu_time(self, cpu_time_str: str) -> float:
        """Parse CPU time to seconds."""
        td = self._parse_time(cpu_time_str)
        return td.total_seconds()

    def get_running_job_stats(self, job_id: str) -> Optional[JobMetrics]:
        """Get statistics for a running job using sstat."""
        metrics = JobMetrics(job_id=job_id, state=JobState.RUNNING)
        metrics.last_updated = datetime.now()

        squeue_cmd = [
            self.slurm.squeue_path, "-j", job_id, "--noheader",
            "-o", "%j|%u|%T|%V|%S|%L|%D|%C|%b|%m|%P"
        ]
        stdout, stderr, rc = self._run_command(squeue_cmd)
        if rc != 0 or not stdout.strip():
            logger.warning(f"Job {job_id} not found in squeue")
            return None

        parts = stdout.strip().split('|')
        if len(parts) >= 11:
            metrics.job_name = parts[0]
            metrics.user = parts[1]
            metrics.state = JobState.from_string(parts[2])
            metrics.submit_time = self._parse_datetime(parts[3])
            metrics.start_time = self._parse_datetime(parts[4])
            time_left = self._parse_time(parts[5])
            metrics.num_nodes = int(parts[6]) if parts[6].isdigit() else 1
            metrics.num_cpus = int(parts[7]) if parts[7].isdigit() else 1
            gres = parts[8]
            if 'gpu' in gres.lower():
                match = re.search(r'gpu[:\w]*:(\d+)', gres.lower())
                if match:
                    metrics.num_gpus = int(match.group(1))
            metrics.memory_requested = self._parse_memory(parts[9])
            metrics.partition = parts[10]
            if metrics.start_time:
                metrics.elapsed_time = datetime.now() - metrics.start_time
                metrics.time_limit = metrics.elapsed_time + time_left

        for step_suffix in ["", ".batch", ".0"]:
            sstat_cmd = [
                self.slurm.sstat_path, "-j", f"{job_id}{step_suffix}",
                "--noheader", "-P", "-o", "JobID,AveCPU,MaxRSS,MaxVMSize,NTasks"
            ]
            stdout, stderr, rc = self._run_command(sstat_cmd)
            if rc == 0 and stdout.strip():
                for line in stdout.strip().split('\n'):
                    parts = line.split('|')
                    if len(parts) >= 5:
                        metrics.cpu_time_total = self._parse_cpu_time(parts[1])
                        metrics.memory_used_max = self._parse_memory(parts[2])
                        break
                break

        metrics.calculate_efficiency()
        return metrics

    def get_completed_job_stats(self, job_id: str) -> Optional[JobMetrics]:
        """Get statistics for a completed job using sacct."""
        metrics = JobMetrics(job_id=job_id)
        metrics.last_updated = datetime.now()

        sacct_cmd = [
            self.slurm.sacct_path, "-j", job_id, "--noheader", "-P",
            "-o", "JobID,JobName,User,State,Submit,Start,End,Elapsed,Timelimit,"
                  "NNodes,NCPUs,ReqMem,MaxRSS,AveCPU,TotalCPU,Partition,AllocTRES,ExitCode"
        ]
        stdout, stderr, rc = self._run_command(sacct_cmd)
        if rc != 0 or not stdout.strip():
            logger.warning(f"Job {job_id} not found in sacct: {stderr}")
            return None

        lines = stdout.strip().split('\n')
        main_line = None
        batch_line = None
        for line in lines:
            parts = line.split('|')
            if parts:
                step_id = parts[0]
                if step_id == job_id or step_id == f"{job_id}.batch":
                    if '.batch' in step_id:
                        batch_line = parts
                    else:
                        main_line = parts

        if not main_line:
            main_line = lines[0].split('|') if lines else None
        if not main_line or len(main_line) < 18:
            logger.warning(f"Incomplete sacct output for job {job_id}")
            return None

        metrics.job_name = main_line[1]
        metrics.user = main_line[2]
        metrics.state = JobState.from_string(main_line[3])
        metrics.submit_time = self._parse_datetime(main_line[4])
        metrics.start_time = self._parse_datetime(main_line[5])
        metrics.end_time = self._parse_datetime(main_line[6])
        metrics.elapsed_time = self._parse_time(main_line[7])
        metrics.time_limit = self._parse_time(main_line[8])
        metrics.num_nodes = int(main_line[9]) if main_line[9].isdigit() else 1
        metrics.num_cpus = int(main_line[10]) if main_line[10].isdigit() else 1

        req_mem = main_line[11]
        mem_multiplier = 1
        if req_mem.endswith('n'):
            mem_multiplier = metrics.num_nodes
            req_mem = req_mem[:-1]
        elif req_mem.endswith('c'):
            mem_multiplier = metrics.num_cpus
            req_mem = req_mem[:-1]
        metrics.memory_requested = self._parse_memory(req_mem) * mem_multiplier
        metrics.partition = main_line[15]

        alloc_gres = main_line[16] if len(main_line) > 16 else ""
        if 'gpu' in alloc_gres.lower():
            match = re.search(r'gpu[:\w]*:(\d+)', alloc_gres.lower())
            if match:
                metrics.num_gpus = int(match.group(1))

        if batch_line and len(batch_line) >= 15:
            metrics.memory_used_max = self._parse_memory(batch_line[12])
            metrics.cpu_time_total = self._parse_cpu_time(batch_line[14])
        else:
            metrics.memory_used_max = self._parse_memory(main_line[12])
            metrics.cpu_time_total = self._parse_cpu_time(main_line[14])

        metrics.calculate_efficiency()
        return metrics

    def get_job_stats(self, job_id: str) -> Optional[JobMetrics]:
        """Get job statistics regardless of job state."""
        state = self.get_job_state(job_id)
        if state.is_running:
            return self.get_running_job_stats(job_id)
        elif state.is_completed:
            return self.get_completed_job_stats(job_id)
        elif state == JobState.PENDING:
            metrics = JobMetrics(job_id=job_id, state=state)
            metrics.last_updated = datetime.now()
            return metrics
        else:
            result = self.get_completed_job_stats(job_id)
            if result:
                return result
            return self.get_running_job_stats(job_id)


# =============================================================================
# Session Card Updater
# =============================================================================

class SessionCardUpdater:
    """Updates Open OnDemand session cards with job efficiency information."""

    CARD_STYLES = """
<style>
.job-efficiency-card {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
    font-size: 13px;
    line-height: 1.4;
    padding: 10px;
    background: #f8f9fa;
    border-radius: 6px;
    margin: 8px 0;
}
.job-efficiency-card h4 {
    margin: 0 0 10px 0;
    padding-bottom: 6px;
    border-bottom: 1px solid #dee2e6;
    color: #495057;
    font-size: 14px;
}
.efficiency-section {
    margin-bottom: 10px;
}
.efficiency-section:last-child {
    margin-bottom: 0;
}
.efficiency-label {
    font-weight: 500;
    color: #6c757d;
    font-size: 11px;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}
.efficiency-row {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 4px 0;
}
.efficiency-value {
    font-weight: 600;
    font-size: 14px;
}
.efficiency-bar {
    height: 6px;
    background: #e9ecef;
    border-radius: 3px;
    overflow: hidden;
    margin-top: 2px;
}
.efficiency-bar-fill {
    height: 100%;
    border-radius: 3px;
    transition: width 0.3s ease;
}
.efficiency-good { color: #28a745; }
.efficiency-warning { color: #ffc107; }
.efficiency-poor { color: #dc3545; }
.efficiency-neutral { color: #6c757d; }
.bar-good { background: #28a745; }
.bar-warning { background: #ffc107; }
.bar-poor { background: #dc3545; }
.recommendation {
    margin-top: 10px;
    padding: 8px;
    background: #fff3cd;
    border: 1px solid #ffc107;
    border-radius: 4px;
    font-size: 12px;
    color: #856404;
}
.recommendation.good {
    background: #d4edda;
    border-color: #28a745;
    color: #155724;
}
.job-summary {
    margin-top: 10px;
    padding: 8px;
    background: #e9ecef;
    border-radius: 4px;
}
.job-summary-row {
    display: flex;
    justify-content: space-between;
    font-size: 12px;
    padding: 2px 0;
}
.last-updated {
    font-size: 10px;
    color: #adb5bd;
    text-align: right;
    margin-top: 8px;
}
.compact .efficiency-row {
    padding: 2px 0;
}
.compact .efficiency-section {
    margin-bottom: 6px;
}
</style>
"""

    def __init__(self, config: Optional[Config] = None):
        self.config = config or Config()
        self.thresholds = self.config.thresholds

    def _get_efficiency_class(self, value: float, good_threshold: float,
                              warning_threshold: float, invert: bool = False) -> str:
        """Get CSS class for efficiency value based on thresholds."""
        if invert:
            if value >= good_threshold:
                return "poor"
            elif value >= warning_threshold:
                return "warning"
            else:
                return "good"
        else:
            if value >= good_threshold:
                return "good"
            elif value >= warning_threshold:
                return "warning"
            else:
                return "poor"

    def _format_duration(self, td: timedelta) -> str:
        """Format timedelta as human-readable string."""
        total_seconds = int(td.total_seconds())
        if total_seconds < 0:
            return "N/A"
        days = total_seconds // 86400
        hours = (total_seconds % 86400) // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60
        parts = []
        if days > 0:
            parts.append(f"{days}d")
        if hours > 0 or days > 0:
            parts.append(f"{hours}h")
        if minutes > 0 or hours > 0 or days > 0:
            parts.append(f"{minutes}m")
        parts.append(f"{seconds}s")
        return " ".join(parts[:3])

    def _format_memory(self, bytes_val: float) -> str:
        """Format bytes as human-readable string."""
        if bytes_val <= 0:
            return "N/A"
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if abs(bytes_val) < 1024.0:
                return f"{bytes_val:.1f} {unit}"
            bytes_val /= 1024.0
        return f"{bytes_val:.1f} PB"

    def _generate_progress_bar(self, value: float, css_class: str) -> str:
        """Generate HTML for a progress bar."""
        value = max(0, min(100, value))
        return f'''
        <div class="efficiency-bar">
            <div class="efficiency-bar-fill bar-{css_class}" style="width: {value:.1f}%"></div>
        </div>
        '''

    def _generate_recommendations(self, metrics: JobMetrics) -> List[str]:
        """Generate efficiency recommendations based on metrics."""
        recommendations = []
        if metrics.cpu_efficiency < self.thresholds.cpu_warning:
            recommendations.append(
                f"‚ö†Ô∏è CPU efficiency is low ({metrics.cpu_efficiency:.1f}%). "
                f"Consider requesting fewer CPUs or optimizing CPU usage."
            )
        if metrics.memory_efficiency > 0:
            if metrics.memory_efficiency < self.thresholds.memory_warning:
                recommendations.append(
                    f"‚ö†Ô∏è Memory usage is low ({metrics.memory_efficiency:.1f}%). "
                    f"Consider requesting less memory to improve job scheduling."
                )
            elif metrics.memory_efficiency > 95:
                recommendations.append(
                    f"‚ö†Ô∏è Memory usage is very high ({metrics.memory_efficiency:.1f}%). "
                    f"Consider requesting more memory to avoid out-of-memory errors."
                )
        if metrics.has_gpus and metrics.gpu_utilization_avg > 0:
            if metrics.gpu_utilization_avg < self.thresholds.gpu_warning:
                recommendations.append(
                    f"‚ö†Ô∏è GPU utilization is low ({metrics.gpu_utilization_avg:.1f}%). "
                    f"Ensure your code is properly utilizing GPUs."
                )
        if metrics.time_efficiency > 0 and metrics.time_efficiency < 10:
            recommendations.append(
                f"‚ÑπÔ∏è Job completed using only {metrics.time_efficiency:.1f}% of the time limit. "
                f"Consider reducing the time limit for better scheduling priority."
            )
        return recommendations

    def generate_running_card_html(self, metrics: JobMetrics) -> str:
        """Generate HTML card content for a running job."""
        compact_class = "compact" if self.config.compact_mode else ""
        cpu_class = self._get_efficiency_class(
            metrics.cpu_efficiency, self.thresholds.cpu_good, self.thresholds.cpu_warning
        )
        mem_class = self._get_efficiency_class(
            metrics.memory_efficiency, self.thresholds.memory_good, self.thresholds.memory_warning
        )

        html = f"""
{self.CARD_STYLES}
<div class="job-efficiency-card {compact_class}">
    <h4>üìä {self.config.card_title}</h4>
    
    <div class="efficiency-section">
        <div class="efficiency-label">CPU Efficiency</div>
        <div class="efficiency-row">
            <span>Utilization</span>
            <span class="efficiency-value efficiency-{cpu_class}">{metrics.cpu_efficiency:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.cpu_efficiency, cpu_class)}
    </div>
    
    <div class="efficiency-section">
        <div class="efficiency-label">Memory Usage</div>
        <div class="efficiency-row">
            <span>{self._format_memory(metrics.memory_used_max)} / {self._format_memory(metrics.memory_requested)}</span>
            <span class="efficiency-value efficiency-{mem_class}">{metrics.memory_efficiency:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.memory_efficiency, mem_class)}
    </div>
"""

        if metrics.has_gpus:
            gpu_class = self._get_efficiency_class(
                metrics.gpu_utilization_avg, self.thresholds.gpu_good, self.thresholds.gpu_warning
            )
            gpu_mem_class = self._get_efficiency_class(
                metrics.gpu_memory_utilization_avg, self.thresholds.gpu_memory_good, self.thresholds.gpu_memory_warning
            )
            html += f"""
    <div class="efficiency-section">
        <div class="efficiency-label">GPU Utilization ({metrics.num_gpus} GPU{'s' if metrics.num_gpus > 1 else ''})</div>
        <div class="efficiency-row">
            <span>Compute</span>
            <span class="efficiency-value efficiency-{gpu_class}">{metrics.gpu_utilization_avg:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.gpu_utilization_avg, gpu_class)}
        <div class="efficiency-row">
            <span>Memory</span>
            <span class="efficiency-value efficiency-{gpu_mem_class}">{metrics.gpu_memory_utilization_avg:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.gpu_memory_utilization_avg, gpu_mem_class)}
    </div>
"""

        html += f"""
    <div class="job-summary">
        <div class="job-summary-row">
            <span>Elapsed Time:</span>
            <span>{self._format_duration(metrics.elapsed_time)}</span>
        </div>
        <div class="job-summary-row">
            <span>Time Limit:</span>
            <span>{self._format_duration(metrics.time_limit)}</span>
        </div>
        <div class="job-summary-row">
            <span>Resources:</span>
            <span>{metrics.num_nodes}N √ó {metrics.num_cpus}C</span>
        </div>
    </div>
"""

        if self.config.show_recommendations:
            recommendations = self._generate_recommendations(metrics)
            if recommendations:
                html += """
    <div class="recommendation">
        <strong>Tips:</strong><br>
"""
                for rec in recommendations:
                    html += f"        {rec}<br>\n"
                html += "    </div>\n"

        updated_str = metrics.last_updated.strftime("%H:%M:%S") if metrics.last_updated else "Unknown"
        html += f"""
    <div class="last-updated">Last updated: {updated_str}</div>
</div>
"""
        return html

    def generate_completed_card_html(self, metrics: JobMetrics) -> str:
        """Generate HTML card content for a completed job."""
        compact_class = "compact" if self.config.compact_mode else ""

        if metrics.state.is_successful:
            status_icon = "‚úÖ"
            status_text = "Completed Successfully"
        elif metrics.state == JobState.CANCELLED:
            status_icon = "üö´"
            status_text = "Cancelled"
        elif metrics.state == JobState.TIMEOUT:
            status_icon = "‚è±Ô∏è"
            status_text = "Timed Out"
        else:
            status_icon = "‚ùå"
            status_text = f"Failed ({metrics.state.value})"

        cpu_class = self._get_efficiency_class(
            metrics.cpu_efficiency, self.thresholds.cpu_good, self.thresholds.cpu_warning
        )
        mem_class = self._get_efficiency_class(
            metrics.memory_efficiency, self.thresholds.memory_good, self.thresholds.memory_warning
        )

        html = f"""
{self.CARD_STYLES}
<div class="job-efficiency-card {compact_class}">
    <h4>{status_icon} Job {status_text}</h4>
    
    <div class="job-summary">
        <div class="job-summary-row">
            <span>Job ID:</span>
            <span>{metrics.job_id}</span>
        </div>
        <div class="job-summary-row">
            <span>Total Runtime:</span>
            <span>{self._format_duration(metrics.elapsed_time)}</span>
        </div>
        <div class="job-summary-row">
            <span>Time Limit:</span>
            <span>{self._format_duration(metrics.time_limit)} ({metrics.time_efficiency:.1f}% used)</span>
        </div>
        <div class="job-summary-row">
            <span>Resources:</span>
            <span>{metrics.num_nodes}N √ó {metrics.num_cpus}C{f' √ó {metrics.num_gpus}G' if metrics.has_gpus else ''}</span>
        </div>
    </div>
    
    <div class="efficiency-section">
        <div class="efficiency-label">Final CPU Efficiency</div>
        <div class="efficiency-row">
            <span>Overall</span>
            <span class="efficiency-value efficiency-{cpu_class}">{metrics.cpu_efficiency:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.cpu_efficiency, cpu_class)}
    </div>
    
    <div class="efficiency-section">
        <div class="efficiency-label">Final Memory Usage</div>
        <div class="efficiency-row">
            <span>Peak: {self._format_memory(metrics.memory_used_max)} / {self._format_memory(metrics.memory_requested)}</span>
            <span class="efficiency-value efficiency-{mem_class}">{metrics.memory_efficiency:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.memory_efficiency, mem_class)}
    </div>
"""

        if metrics.has_gpus:
            gpu_class = self._get_efficiency_class(
                metrics.gpu_utilization_avg, self.thresholds.gpu_good, self.thresholds.gpu_warning
            )
            html += f"""
    <div class="efficiency-section">
        <div class="efficiency-label">GPU Summary ({metrics.num_gpus} GPU{'s' if metrics.num_gpus > 1 else ''})</div>
        <div class="efficiency-row">
            <span>Average Utilization</span>
            <span class="efficiency-value efficiency-{gpu_class}">{metrics.gpu_utilization_avg:.1f}%</span>
        </div>
        {self._generate_progress_bar(metrics.gpu_utilization_avg, gpu_class)}
    </div>
"""

        if self.config.show_recommendations:
            recommendations = self._generate_recommendations(metrics)
            if recommendations:
                html += """
    <div class="recommendation">
        <strong>Suggestions for Future Jobs:</strong><br>
"""
                for rec in recommendations:
                    html += f"        {rec}<br>\n"
                html += "    </div>\n"
            elif metrics.cpu_efficiency > self.thresholds.cpu_good and metrics.memory_efficiency > self.thresholds.memory_warning:
                html += """
    <div class="recommendation good">
        ‚ú® Great job! Resource utilization was efficient.
    </div>
"""

        html += "</div>\n"
        return html

    def generate_card_html(self, metrics: JobMetrics) -> str:
        """Generate appropriate HTML card based on job state."""
        if metrics.state.is_completed:
            return self.generate_completed_card_html(metrics)
        else:
            return self.generate_running_card_html(metrics)

    def update_session_card(self, session_path: Path, metrics: JobMetrics) -> bool:
        """Update the session card HTML file with job efficiency data."""
        info_html_path = session_path / "info.html"
        try:
            new_content = self.generate_card_html(metrics)
            with open(info_html_path, 'w') as f:
                f.write(new_content)
            logger.debug(f"Updated session card: {info_html_path}")
            return True
        except PermissionError:
            logger.error(f"Permission denied writing to: {info_html_path}")
            return False
        except Exception as e:
            logger.error(f"Error updating session card: {e}")
            return False

    def find_session_for_job(self, user: str, job_id: str) -> Optional[Path]:
        """Find the OOD session directory for a given Slurm job."""
        user_session_path = self.config.get_user_session_path(user)
        if not user_session_path.exists():
            logger.debug(f"User session path does not exist: {user_session_path}")
            return None
        for session_dir in user_session_path.iterdir():
            if not session_dir.is_dir():
                continue
            job_id_file = session_dir / "job_id"
            if job_id_file.exists():
                try:
                    with open(job_id_file, 'r') as f:
                        stored_job_id = f.read().strip()
                    if stored_job_id == job_id:
                        return session_dir
                except Exception as e:
                    logger.debug(f"Error reading job_id file: {e}")
                    continue
        logger.debug(f"No session found for job {job_id}")
        return None

    def list_active_sessions(self, user: str) -> List[tuple]:
        """List all active OOD sessions for a user."""
        sessions = []
        user_session_path = self.config.get_user_session_path(user)
        if not user_session_path.exists():
            return sessions
        for session_dir in user_session_path.iterdir():
            if not session_dir.is_dir():
                continue
            job_id_file = session_dir / "job_id"
            if job_id_file.exists():
                try:
                    with open(job_id_file, 'r') as f:
                        job_id = f.read().strip()
                    sessions.append((session_dir, job_id))
                except Exception:
                    continue
        return sessions


# =============================================================================
# CLI Commands
# =============================================================================

def setup_logging(verbose: bool = False, debug: bool = False) -> None:
    """Configure logging based on command line options."""
    if debug:
        level = logging.DEBUG
    elif verbose:
        level = logging.INFO
    else:
        level = logging.WARNING
    logging.basicConfig(level=level, format='%(levelname)s: %(message)s')


def _make_bar(value: float, width: int = 20) -> str:
    """Create a simple ASCII progress bar."""
    value = max(0, min(100, value))
    filled = int(width * value / 100)
    empty = width - filled
    return f"[{'‚ñà' * filled}{'‚ñë' * empty}]"


def _get_recommendations(metrics: JobMetrics, config: Config) -> List[str]:
    """Generate efficiency recommendations."""
    recs = []
    thresholds = config.thresholds
    if metrics.cpu_efficiency < thresholds.cpu_warning and metrics.cpu_efficiency > 0:
        recs.append(f"Low CPU efficiency ({metrics.cpu_efficiency:.0f}%). Consider requesting fewer CPUs.")
    if metrics.memory_efficiency < thresholds.memory_warning and metrics.memory_efficiency > 0:
        recs.append(f"Low memory usage ({metrics.memory_efficiency:.0f}%). Consider requesting less memory.")
    elif metrics.memory_efficiency > 95:
        recs.append(f"High memory usage ({metrics.memory_efficiency:.0f}%). Consider requesting more memory.")
    if metrics.has_gpus and metrics.gpu_utilization_avg < thresholds.gpu_warning and metrics.gpu_utilization_avg > 0:
        recs.append(f"Low GPU utilization ({metrics.gpu_utilization_avg:.0f}%). Ensure code is GPU-optimized.")
    if metrics.state.is_completed and metrics.time_efficiency < 25:
        recs.append(f"Only used {metrics.time_efficiency:.0f}% of time limit. Request less time for faster scheduling.")
    return recs


@dataclass
class ReportStats:
    """Aggregated statistics for a report."""
    total_jobs: int = 0
    completed_jobs: int = 0
    failed_jobs: int = 0
    cancelled_jobs: int = 0
    total_cpu_hours_requested: float = 0.0
    total_cpu_hours_used: float = 0.0
    total_memory_gb_hours_requested: float = 0.0
    total_memory_gb_hours_used: float = 0.0
    total_gpu_hours_requested: float = 0.0
    avg_cpu_efficiency: float = 0.0
    avg_memory_efficiency: float = 0.0
    avg_time_efficiency: float = 0.0
    jobs_by_user: Dict[str, int] = field(default_factory=dict)
    jobs_by_partition: Dict[str, int] = field(default_factory=dict)
    efficiency_by_user: Dict[str, Dict[str, float]] = field(default_factory=dict)
    low_efficiency_jobs: List[Dict[str, Any]] = field(default_factory=list)

    @property
    def cpu_waste_hours(self) -> float:
        return self.total_cpu_hours_requested - self.total_cpu_hours_used

    @property
    def overall_cpu_efficiency(self) -> float:
        if self.total_cpu_hours_requested > 0:
            return (self.total_cpu_hours_used / self.total_cpu_hours_requested) * 100
        return 0.0

    @property
    def overall_memory_efficiency(self) -> float:
        if self.total_memory_gb_hours_requested > 0:
            return (self.total_memory_gb_hours_used / self.total_memory_gb_hours_requested) * 100
        return 0.0


def _query_jobs_for_report(
    config: Config,
    start_date: str,
    end_date: str,
    user: Optional[str] = None,
    account: Optional[str] = None,
    partition: Optional[str] = None,
    all_users: bool = False,
) -> List[Dict[str, Any]]:
    """Query sacct for completed jobs within date range (excludes running jobs)."""
    slurm = config.slurm
    
    # First query: get main job info with --allocations
    cmd = [
        slurm.sacct_path,
        "--starttime", start_date,
        "--endtime", end_date,
        "--noheader", "-P",
        "--allocations",  # Only main job entries, not steps
        # Exclude running/pending jobs - only include jobs that have finished
        "--state", "COMPLETED,FAILED,CANCELLED,TIMEOUT,NODE_FAIL,OUT_OF_MEMORY,PREEMPTED,DEADLINE",
        "-o", "JobID,JobName,User,Account,State,Partition,Submit,Start,End,Elapsed,"
              "Timelimit,NNodes,NCPUs,ReqMem,AllocTRES,ExitCode"
    ]
    
    # Query all users if requested (for leaderboard) or specific user
    if all_users:
        cmd.append("--allusers")
    elif user:
        cmd.extend(["--user", user])
    if account:
        cmd.extend(["--account", account])
    if partition:
        cmd.extend(["--partition", partition])
    
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        if result.returncode != 0:
            logger.error(f"sacct failed: {result.stderr}")
            return []
    except Exception as e:
        logger.error(f"Error running sacct: {e}")
        return []
    
    # Parse main job entries
    jobs = {}
    for line in result.stdout.strip().split('\n'):
        if not line:
            continue
        parts = line.split('|')
        if len(parts) < 16:
            continue
        
        job_id = parts[0]
        jobs[job_id] = {
            'job_id': job_id,
            'job_name': parts[1],
            'user': parts[2],
            'account': parts[3],
            'state': parts[4],
            'partition': parts[5],
            'submit': parts[6],
            'start': parts[7],
            'end': parts[8],
            'elapsed': parts[9],
            'timelimit': parts[10],
            'nodes': parts[11],
            'cpus': parts[12],
            'reqmem': parts[13],
            'alloctres': parts[14],
            'exitcode': parts[15],
            'maxrss': '',
            'totalcpu': '',
        }
    
    if not jobs:
        return []
    
    # Second query: get MaxRSS and TotalCPU from job steps (batch step has the real data)
    # Query all steps for the jobs we found
    job_ids = ','.join(jobs.keys())
    cmd2 = [
        slurm.sacct_path,
        "-j", job_ids,
        "--noheader", "-P",
        "-o", "JobID,MaxRSS,TotalCPU"
    ]
    
    try:
        result2 = subprocess.run(cmd2, capture_output=True, text=True, timeout=120)
        if result2.returncode == 0:
            for line in result2.stdout.strip().split('\n'):
                if not line:
                    continue
                parts = line.split('|')
                if len(parts) < 3:
                    continue
                
                step_id = parts[0]
                maxrss = parts[1]
                totalcpu = parts[2]
                
                # Extract base job ID (handle "12345.batch" -> "12345")
                base_job_id = step_id.split('.')[0]
                
                if base_job_id in jobs:
                    # Prefer .batch step data, but take any non-empty values
                    # .batch step typically has the most accurate resource usage
                    if '.batch' in step_id:
                        if maxrss:
                            jobs[base_job_id]['maxrss'] = maxrss
                        if totalcpu:
                            jobs[base_job_id]['totalcpu'] = totalcpu
                    elif not jobs[base_job_id]['maxrss'] and maxrss:
                        jobs[base_job_id]['maxrss'] = maxrss
                    elif not jobs[base_job_id]['totalcpu'] and totalcpu:
                        jobs[base_job_id]['totalcpu'] = totalcpu
    except Exception as e:
        logger.warning(f"Could not get job step details: {e}")
    
    return list(jobs.values())


def _calculate_report_stats(
    jobs: List[Dict[str, Any]],
    config: Config,
    low_efficiency_threshold: float = 25.0,
) -> ReportStats:
    """Calculate aggregated statistics from job list."""
    stats = ReportStats()
    job_stats_helper = JobStats(config)
    
    cpu_efficiencies = []
    mem_efficiencies = []
    time_efficiencies = []
    
    for job in jobs:
        stats.total_jobs += 1
        user = job['user']
        partition = job['partition']
        state = job['state'].split()[0]  # Handle "COMPLETED by ..." etc.
        
        # Count by state
        if 'COMPLETED' in state:
            stats.completed_jobs += 1
        elif state in ('FAILED', 'NODE_FAIL', 'TIMEOUT', 'OUT_OF_MEMORY', 'DEADLINE', 'BOOT_FAIL'):
            stats.failed_jobs += 1
        elif 'CANCELLED' in state or state == 'PREEMPTED':
            stats.cancelled_jobs += 1
        
        # Count by user/partition
        stats.jobs_by_user[user] = stats.jobs_by_user.get(user, 0) + 1
        stats.jobs_by_partition[partition] = stats.jobs_by_partition.get(partition, 0) + 1
        
        # Parse resources
        try:
            cpus = int(job['cpus']) if job['cpus'].isdigit() else 1
        except:
            cpus = 1
        
        elapsed = job_stats_helper._parse_time(job['elapsed'])
        timelimit = job_stats_helper._parse_time(job['timelimit'])
        elapsed_hours = elapsed.total_seconds() / 3600
        timelimit_hours = timelimit.total_seconds() / 3600 if timelimit.total_seconds() > 0 else elapsed_hours
        
        # CPU hours
        cpu_hours_requested = cpus * timelimit_hours
        cpu_time = job_stats_helper._parse_cpu_time(job['totalcpu'])
        cpu_hours_used = cpu_time / 3600
        
        stats.total_cpu_hours_requested += cpu_hours_requested
        stats.total_cpu_hours_used += cpu_hours_used
        
        # Memory
        reqmem_str = job['reqmem']
        nodes = int(job['nodes']) if job['nodes'].isdigit() else 1
        mem_multiplier = 1
        if reqmem_str.endswith('n'):
            mem_multiplier = nodes
            reqmem_str = reqmem_str[:-1]
        elif reqmem_str.endswith('c'):
            mem_multiplier = cpus
            reqmem_str = reqmem_str[:-1]
        
        mem_requested = job_stats_helper._parse_memory(reqmem_str) * mem_multiplier
        mem_used = job_stats_helper._parse_memory(job['maxrss'])
        
        mem_gb_hours_requested = (mem_requested / (1024**3)) * elapsed_hours
        mem_gb_hours_used = (mem_used / (1024**3)) * elapsed_hours
        
        stats.total_memory_gb_hours_requested += mem_gb_hours_requested
        stats.total_memory_gb_hours_used += mem_gb_hours_used
        
        # GPUs
        alloctres = job['alloctres']
        if 'gpu' in alloctres.lower():
            match = re.search(r'gpu[=:]?(\d+)', alloctres.lower())
            if match:
                gpu_count = int(match.group(1))
                stats.total_gpu_hours_requested += gpu_count * elapsed_hours
        
        # Calculate efficiencies
        cpu_eff = 0.0
        if cpu_hours_requested > 0:
            cpu_eff = (cpu_hours_used / cpu_hours_requested) * 100
            cpu_eff = min(100.0, max(0.0, cpu_eff))
            cpu_efficiencies.append(cpu_eff)
        
        mem_eff = 0.0
        if mem_requested > 0:
            mem_eff = (mem_used / mem_requested) * 100
            mem_eff = min(100.0, max(0.0, mem_eff))
            mem_efficiencies.append(mem_eff)
        
        time_eff = 0.0
        if timelimit_hours > 0:
            time_eff = (elapsed_hours / timelimit_hours) * 100
            time_eff = min(100.0, max(0.0, time_eff))
            time_efficiencies.append(time_eff)
        
        # Track per-user efficiency
        if user not in stats.efficiency_by_user:
            stats.efficiency_by_user[user] = {
                'cpu_sum': 0.0, 'mem_sum': 0.0, 'count': 0
            }
        stats.efficiency_by_user[user]['cpu_sum'] += cpu_eff
        stats.efficiency_by_user[user]['mem_sum'] += mem_eff
        stats.efficiency_by_user[user]['count'] += 1
        
        # Track low efficiency jobs
        if cpu_eff < low_efficiency_threshold and cpu_eff > 0:
            stats.low_efficiency_jobs.append({
                'job_id': job['job_id'],
                'user': user,
                'cpu_efficiency': cpu_eff,
                'mem_efficiency': mem_eff,
                'cpu_hours_wasted': cpu_hours_requested - cpu_hours_used,
            })
    
    # Calculate averages
    if cpu_efficiencies:
        stats.avg_cpu_efficiency = sum(cpu_efficiencies) / len(cpu_efficiencies)
    if mem_efficiencies:
        stats.avg_memory_efficiency = sum(mem_efficiencies) / len(mem_efficiencies)
    if time_efficiencies:
        stats.avg_time_efficiency = sum(time_efficiencies) / len(time_efficiencies)
    
    # Calculate per-user averages
    for user, data in stats.efficiency_by_user.items():
        if data['count'] > 0:
            data['avg_cpu'] = data['cpu_sum'] / data['count']
            data['avg_mem'] = data['mem_sum'] / data['count']
    
    # Sort low efficiency jobs by waste
    stats.low_efficiency_jobs.sort(key=lambda x: x['cpu_hours_wasted'], reverse=True)
    stats.low_efficiency_jobs = stats.low_efficiency_jobs[:10]  # Top 10
    
    return stats


def _format_report_text(stats: ReportStats, title: str) -> str:
    """Format report as plain text."""
    lines = []
    lines.append("=" * 70)
    lines.append(f"  {title}")
    lines.append("=" * 70)
    lines.append("")
    
    # Summary
    lines.append("SUMMARY")
    lines.append("-" * 40)
    lines.append(f"Total Jobs:           {stats.total_jobs}")
    lines.append(f"  Completed:          {stats.completed_jobs}")
    lines.append(f"  Failed:             {stats.failed_jobs}")
    lines.append(f"  Cancelled:          {stats.cancelled_jobs}")
    lines.append("")
    
    # Resource usage
    lines.append("RESOURCE USAGE")
    lines.append("-" * 40)
    lines.append(f"CPU Hours Requested:  {stats.total_cpu_hours_requested:,.1f}")
    lines.append(f"CPU Hours Used:       {stats.total_cpu_hours_used:,.1f}")
    lines.append(f"CPU Hours Wasted:     {stats.cpu_waste_hours:,.1f}")
    lines.append(f"GPU Hours Requested:  {stats.total_gpu_hours_requested:,.1f}")
    lines.append("")
    
    # Efficiency
    lines.append("EFFICIENCY")
    lines.append("-" * 40)
    cpu_bar = _make_bar(stats.overall_cpu_efficiency)
    mem_bar = _make_bar(stats.overall_memory_efficiency)
    avg_cpu_bar = _make_bar(stats.avg_cpu_efficiency)
    avg_mem_bar = _make_bar(stats.avg_memory_efficiency)
    lines.append(f"Overall CPU:          {cpu_bar} {stats.overall_cpu_efficiency:5.1f}%")
    lines.append(f"Overall Memory:       {mem_bar} {stats.overall_memory_efficiency:5.1f}%")
    lines.append(f"Avg Job CPU:          {avg_cpu_bar} {stats.avg_cpu_efficiency:5.1f}%")
    lines.append(f"Avg Job Memory:       {avg_mem_bar} {stats.avg_memory_efficiency:5.1f}%")
    lines.append("")
    
    # Jobs by partition
    if stats.jobs_by_partition:
        lines.append("JOBS BY PARTITION")
        lines.append("-" * 40)
        for part, count in sorted(stats.jobs_by_partition.items(), key=lambda x: -x[1]):
            lines.append(f"  {part:<20} {count:>6}")
        lines.append("")
    
    # Low efficiency jobs
    if stats.low_efficiency_jobs:
        lines.append("LOW EFFICIENCY JOBS (top 10 by CPU hours wasted)")
        lines.append("-" * 40)
        lines.append(f"  {'JobID':<12} {'User':<12} {'CPU Eff':>8} {'Wasted Hrs':>12}")
        for job in stats.low_efficiency_jobs:
            lines.append(
                f"  {job['job_id']:<12} {job['user']:<12} "
                f"{job['cpu_efficiency']:>7.1f}% {job['cpu_hours_wasted']:>11.1f}"
            )
        lines.append("")
    
    # Recommendations
    lines.append("RECOMMENDATIONS")
    lines.append("-" * 40)
    recs = []
    if stats.overall_cpu_efficiency < 50:
        recs.append("‚Ä¢ Overall CPU efficiency is low. Encourage users to request fewer CPUs or optimize code for parallelism.")
    if stats.overall_memory_efficiency < 40:
        recs.append("‚Ä¢ Overall memory efficiency is low. Users may be over-requesting memory.")
    if stats.cpu_waste_hours > 1000:
        recs.append(f"‚Ä¢ {stats.cpu_waste_hours:,.0f} CPU hours wasted this period. Consider user training on resource estimation.")
    if stats.failed_jobs > stats.total_jobs * 0.1:
        failure_pct = (stats.failed_jobs / stats.total_jobs * 100) if stats.total_jobs > 0 else 0
        recs.append(f"‚Ä¢ High failure rate ({failure_pct:.1f}%). Investigate common failure causes.")
    if stats.cancelled_jobs > stats.total_jobs * 0.15:
        cancel_pct = (stats.cancelled_jobs / stats.total_jobs * 100) if stats.total_jobs > 0 else 0
        recs.append(f"‚Ä¢ High cancellation rate ({cancel_pct:.1f}%). Users may need help with job time estimation.")
    if stats.low_efficiency_jobs:
        recs.append(f"‚Ä¢ Contact users with consistently low-efficiency jobs for targeted assistance.")
    if not recs:
        recs.append("‚Ä¢ Resource utilization looks healthy. Keep up the good work!")
    for rec in recs:
        lines.append(rec)
    lines.append("")
    
    return "\n".join(lines)


def _format_report_csv(stats: ReportStats, jobs: List[Dict[str, Any]], config: Config) -> str:
    """Format report as CSV with per-job details."""
    lines = []
    job_stats_helper = JobStats(config)
    
    # Header
    lines.append("job_id,user,account,state,partition,cpus,elapsed_hours,"
                 "cpu_hours_requested,cpu_hours_used,cpu_efficiency,"
                 "mem_requested_gb,mem_used_gb,mem_efficiency")
    
    for job in jobs:
        try:
            cpus = int(job['cpus']) if job['cpus'].isdigit() else 1
        except:
            cpus = 1
        
        elapsed = job_stats_helper._parse_time(job['elapsed'])
        timelimit = job_stats_helper._parse_time(job['timelimit'])
        elapsed_hours = elapsed.total_seconds() / 3600
        timelimit_hours = timelimit.total_seconds() / 3600 if timelimit.total_seconds() > 0 else elapsed_hours
        
        cpu_hours_requested = cpus * timelimit_hours
        cpu_time = job_stats_helper._parse_cpu_time(job['totalcpu'])
        cpu_hours_used = cpu_time / 3600
        cpu_eff = (cpu_hours_used / cpu_hours_requested * 100) if cpu_hours_requested > 0 else 0
        
        reqmem_str = job['reqmem']
        nodes = int(job['nodes']) if job['nodes'].isdigit() else 1
        mem_multiplier = 1
        if reqmem_str.endswith('n'):
            mem_multiplier = nodes
            reqmem_str = reqmem_str[:-1]
        elif reqmem_str.endswith('c'):
            mem_multiplier = cpus
            reqmem_str = reqmem_str[:-1]
        
        mem_requested = job_stats_helper._parse_memory(reqmem_str) * mem_multiplier
        mem_used = job_stats_helper._parse_memory(job['maxrss'])
        mem_eff = (mem_used / mem_requested * 100) if mem_requested > 0 else 0
        
        lines.append(
            f"{job['job_id']},{job['user']},{job['account']},{job['state']},{job['partition']},"
            f"{cpus},{elapsed_hours:.2f},{cpu_hours_requested:.2f},{cpu_hours_used:.2f},{cpu_eff:.1f},"
            f"{mem_requested/(1024**3):.2f},{mem_used/(1024**3):.2f},{mem_eff:.1f}"
        )
    
    return "\n".join(lines)


def _format_report_json(stats: ReportStats) -> str:
    """Format report as JSON."""
    data = {
        'summary': {
            'total_jobs': stats.total_jobs,
            'completed_jobs': stats.completed_jobs,
            'failed_jobs': stats.failed_jobs,
            'cancelled_jobs': stats.cancelled_jobs,
        },
        'resources': {
            'cpu_hours_requested': round(stats.total_cpu_hours_requested, 2),
            'cpu_hours_used': round(stats.total_cpu_hours_used, 2),
            'cpu_hours_wasted': round(stats.cpu_waste_hours, 2),
            'gpu_hours_requested': round(stats.total_gpu_hours_requested, 2),
            'memory_gb_hours_requested': round(stats.total_memory_gb_hours_requested, 2),
            'memory_gb_hours_used': round(stats.total_memory_gb_hours_used, 2),
        },
        'efficiency': {
            'overall_cpu_percent': round(stats.overall_cpu_efficiency, 2),
            'overall_memory_percent': round(stats.overall_memory_efficiency, 2),
            'avg_job_cpu_percent': round(stats.avg_cpu_efficiency, 2),
            'avg_job_memory_percent': round(stats.avg_memory_efficiency, 2),
        },
        'jobs_by_partition': stats.jobs_by_partition,
        'jobs_by_user': stats.jobs_by_user,
        'user_efficiency': {
            user: {
                'job_count': data['count'],
                'avg_cpu_efficiency': round(data.get('avg_cpu', 0), 2),
                'avg_memory_efficiency': round(data.get('avg_mem', 0), 2),
            }
            for user, data in stats.efficiency_by_user.items()
        },
        'low_efficiency_jobs': stats.low_efficiency_jobs,
    }
    return json.dumps(data, indent=2)


def _format_report_html(stats: ReportStats, title: str) -> str:
    """Format report as HTML."""
    html = f"""<!DOCTYPE html>
<html>
<head>
    <title>{title}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; }}
        h1 {{ color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
        h2 {{ color: #555; margin-top: 30px; }}
        .card {{ background: white; border-radius: 8px; padding: 20px; margin: 15px 0; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .stat-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }}
        .stat {{ text-align: center; padding: 15px; background: #f8f9fa; border-radius: 6px; }}
        .stat-value {{ font-size: 2em; font-weight: bold; color: #007bff; }}
        .stat-label {{ color: #666; font-size: 0.9em; margin-top: 5px; }}
        table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}
        th, td {{ padding: 10px; text-align: left; border-bottom: 1px solid #ddd; }}
        th {{ background: #f8f9fa; font-weight: 600; }}
        tr:hover {{ background: #f5f5f5; }}
        .progress {{ background: #e9ecef; border-radius: 4px; height: 20px; overflow: hidden; }}
        .progress-bar {{ height: 100%; transition: width 0.3s; }}
        .progress-good {{ background: #28a745; }}
        .progress-warning {{ background: #ffc107; }}
        .progress-danger {{ background: #dc3545; }}
    </style>
</head>
<body>
<div class="container">
    <h1>{title}</h1>
    
    <div class="card">
        <h2>Summary</h2>
        <div class="stat-grid">
            <div class="stat">
                <div class="stat-value">{stats.total_jobs}</div>
                <div class="stat-label">Total Jobs</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.completed_jobs}</div>
                <div class="stat-label">Completed</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.failed_jobs}</div>
                <div class="stat-label">Failed</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.cancelled_jobs}</div>
                <div class="stat-label">Cancelled</div>
            </div>
        </div>
    </div>
    
    <div class="card">
        <h2>Resource Usage</h2>
        <div class="stat-grid">
            <div class="stat">
                <div class="stat-value">{stats.total_cpu_hours_requested:,.0f}</div>
                <div class="stat-label">CPU Hours Requested</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.total_cpu_hours_used:,.0f}</div>
                <div class="stat-label">CPU Hours Used</div>
            </div>
            <div class="stat">
                <div class="stat-value" style="color: #dc3545;">{stats.cpu_waste_hours:,.0f}</div>
                <div class="stat-label">CPU Hours Wasted</div>
            </div>
            <div class="stat">
                <div class="stat-value">{stats.total_gpu_hours_requested:,.0f}</div>
                <div class="stat-label">GPU Hours</div>
            </div>
        </div>
    </div>
    
    <div class="card">
        <h2>Efficiency</h2>
        <table>
            <tr>
                <td style="width: 200px;">Overall CPU Efficiency</td>
                <td>
                    <div class="progress">
                        <div class="progress-bar {'progress-good' if stats.overall_cpu_efficiency >= 70 else 'progress-warning' if stats.overall_cpu_efficiency >= 40 else 'progress-danger'}" style="width: {stats.overall_cpu_efficiency}%;"></div>
                    </div>
                </td>
                <td style="width: 80px; text-align: right;">{stats.overall_cpu_efficiency:.1f}%</td>
            </tr>
            <tr>
                <td>Overall Memory Efficiency</td>
                <td>
                    <div class="progress">
                        <div class="progress-bar {'progress-good' if stats.overall_memory_efficiency >= 60 else 'progress-warning' if stats.overall_memory_efficiency >= 30 else 'progress-danger'}" style="width: {stats.overall_memory_efficiency}%;"></div>
                    </div>
                </td>
                <td style="text-align: right;">{stats.overall_memory_efficiency:.1f}%</td>
            </tr>
            <tr>
                <td>Average Job CPU Efficiency</td>
                <td>
                    <div class="progress">
                        <div class="progress-bar {'progress-good' if stats.avg_cpu_efficiency >= 70 else 'progress-warning' if stats.avg_cpu_efficiency >= 40 else 'progress-danger'}" style="width: {stats.avg_cpu_efficiency}%;"></div>
                    </div>
                </td>
                <td style="text-align: right;">{stats.avg_cpu_efficiency:.1f}%</td>
            </tr>
        </table>
    </div>
"""
    
    # Low efficiency jobs
    if stats.low_efficiency_jobs:
        html += """
    <div class="card">
        <h2>Low Efficiency Jobs (Top 10)</h2>
        <table>
            <thead>
                <tr><th>Job ID</th><th>User</th><th>CPU Efficiency</th><th>CPU Hours Wasted</th></tr>
            </thead>
            <tbody>
"""
        for job in stats.low_efficiency_jobs:
            html += f"            <tr><td>{job['job_id']}</td><td>{job['user']}</td><td>{job['cpu_efficiency']:.1f}%</td><td>{job['cpu_hours_wasted']:.1f}</td></tr>\n"
        html += """            </tbody>
        </table>
    </div>
"""
    
    # Recommendations
    html += """
    <div class="card">
        <h2>Recommendations</h2>
        <ul style="line-height: 1.8; color: #333;">
"""
    recs = []
    if stats.overall_cpu_efficiency < 50:
        recs.append("Overall CPU efficiency is low. Encourage users to request fewer CPUs or optimize code for parallelism.")
    if stats.overall_memory_efficiency < 40:
        recs.append("Overall memory efficiency is low. Users may be over-requesting memory.")
    if stats.cpu_waste_hours > 1000:
        recs.append(f"{stats.cpu_waste_hours:,.0f} CPU hours wasted this period. Consider user training on resource estimation.")
    if stats.failed_jobs > stats.total_jobs * 0.1:
        failure_pct = (stats.failed_jobs / stats.total_jobs * 100) if stats.total_jobs > 0 else 0
        recs.append(f"High failure rate ({failure_pct:.1f}%). Investigate common failure causes.")
    if stats.cancelled_jobs > stats.total_jobs * 0.15:
        cancel_pct = (stats.cancelled_jobs / stats.total_jobs * 100) if stats.total_jobs > 0 else 0
        recs.append(f"High cancellation rate ({cancel_pct:.1f}%). Users may need help with job time estimation.")
    if stats.low_efficiency_jobs:
        recs.append("Contact users with consistently low-efficiency jobs for targeted assistance.")
    if not recs:
        recs.append("Resource utilization looks healthy. Keep up the good work!")
    for rec in recs:
        html += f"            <li>{rec}</li>\n"
    html += """        </ul>
    </div>
"""
    
    html += """
</div>
</body>
</html>
"""
    return html


def cmd_leaderboard(args: argparse.Namespace) -> int:
    """Generate user efficiency leaderboard."""
    config = load_config(args.config)
    
    # Calculate date range
    end_date = datetime.now()
    start_date = end_date - timedelta(days=args.days)
    start_str = start_date.strftime("%Y-%m-%d")
    end_str = end_date.strftime("%Y-%m-%d")
    
    if not args.quiet:
        print(f"Querying jobs from {start_str} to {end_str}...", file=sys.stderr)
    
    # Query all users' jobs for leaderboard
    jobs = _query_jobs_for_report(
        config,
        start_str,
        end_str,
        account=args.account,
        partition=args.partition,
        all_users=True,
    )
    
    if not jobs:
        print("No jobs found in the specified time period.", file=sys.stderr)
        return 1
    
    if not args.quiet:
        print(f"Found {len(jobs)} jobs. Calculating user statistics...", file=sys.stderr)
    
    # Calculate per-user statistics
    job_stats_helper = JobStats(config)
    user_stats: Dict[str, Dict[str, Any]] = {}
    
    for job in jobs:
        user = job['user']
        if user not in user_stats:
            user_stats[user] = {
                'jobs': 0,
                'completed': 0,
                'cpu_hours_requested': 0.0,
                'cpu_hours_used': 0.0,
                'cpu_eff_sum': 0.0,
                'mem_eff_sum': 0.0,
                'eff_count': 0,
            }
        
        user_stats[user]['jobs'] += 1
        state = job['state'].split()[0]
        if 'COMPLETED' in state:
            user_stats[user]['completed'] += 1
        
        # Parse resources
        try:
            cpus = int(job['cpus']) if job['cpus'].isdigit() else 1
        except:
            cpus = 1
        
        elapsed = job_stats_helper._parse_time(job['elapsed'])
        timelimit = job_stats_helper._parse_time(job['timelimit'])
        elapsed_hours = elapsed.total_seconds() / 3600
        timelimit_hours = timelimit.total_seconds() / 3600 if timelimit.total_seconds() > 0 else elapsed_hours
        
        cpu_hours_requested = cpus * timelimit_hours
        cpu_time = job_stats_helper._parse_cpu_time(job['totalcpu'])
        cpu_hours_used = cpu_time / 3600
        
        user_stats[user]['cpu_hours_requested'] += cpu_hours_requested
        user_stats[user]['cpu_hours_used'] += cpu_hours_used
        
        # Calculate efficiency for this job
        cpu_eff = 0.0
        if cpu_hours_requested > 0:
            cpu_eff = (cpu_hours_used / cpu_hours_requested) * 100
            cpu_eff = min(100.0, max(0.0, cpu_eff))
        
        reqmem_str = job['reqmem']
        nodes = int(job['nodes']) if job['nodes'].isdigit() else 1
        mem_multiplier = 1
        if reqmem_str.endswith('n'):
            mem_multiplier = nodes
            reqmem_str = reqmem_str[:-1]
        elif reqmem_str.endswith('c'):
            mem_multiplier = cpus
            reqmem_str = reqmem_str[:-1]
        
        mem_requested = job_stats_helper._parse_memory(reqmem_str) * mem_multiplier
        mem_used = job_stats_helper._parse_memory(job['maxrss'])
        
        mem_eff = 0.0
        if mem_requested > 0:
            mem_eff = (mem_used / mem_requested) * 100
            mem_eff = min(100.0, max(0.0, mem_eff))
        
        if cpu_eff > 0 or mem_eff > 0:
            user_stats[user]['cpu_eff_sum'] += cpu_eff
            user_stats[user]['mem_eff_sum'] += mem_eff
            user_stats[user]['eff_count'] += 1
    
    # Calculate averages and sort
    leaderboard = []
    for user, stats in user_stats.items():
        if stats['eff_count'] > 0:
            avg_cpu_eff = stats['cpu_eff_sum'] / stats['eff_count']
            avg_mem_eff = stats['mem_eff_sum'] / stats['eff_count']
        else:
            avg_cpu_eff = 0.0
            avg_mem_eff = 0.0
        
        # Combined score (weighted average: 60% CPU, 40% memory)
        combined_score = (avg_cpu_eff * 0.6) + (avg_mem_eff * 0.4)
        
        cpu_waste = stats['cpu_hours_requested'] - stats['cpu_hours_used']
        
        leaderboard.append({
            'user': user,
            'jobs': stats['jobs'],
            'completed': stats['completed'],
            'avg_cpu_eff': avg_cpu_eff,
            'avg_mem_eff': avg_mem_eff,
            'combined_score': combined_score,
            'cpu_hours_used': stats['cpu_hours_used'],
            'cpu_waste': cpu_waste,
        })
    
    # Sort by combined score (descending) for efficiency ranking
    if args.sort == 'efficiency':
        leaderboard.sort(key=lambda x: x['combined_score'], reverse=True)
    elif args.sort == 'cpu':
        leaderboard.sort(key=lambda x: x['avg_cpu_eff'], reverse=True)
    elif args.sort == 'memory':
        leaderboard.sort(key=lambda x: x['avg_mem_eff'], reverse=True)
    elif args.sort == 'jobs':
        leaderboard.sort(key=lambda x: x['jobs'], reverse=True)
    elif args.sort == 'waste':
        leaderboard.sort(key=lambda x: x['cpu_waste'], reverse=True)
    
    # Apply minimum jobs filter
    if args.min_jobs > 0:
        leaderboard = [u for u in leaderboard if u['jobs'] >= args.min_jobs]
    
    # Limit results
    if args.top:
        leaderboard = leaderboard[:args.top]
    
    # Output
    if args.format == 'json':
        output = json.dumps({
            'period': {'start': start_str, 'end': end_str, 'days': args.days},
            'leaderboard': leaderboard,
        }, indent=2)
    elif args.format == 'html':
        output = _format_leaderboard_html(leaderboard, start_str, end_str, args.days)
    else:
        output = _format_leaderboard_text(leaderboard, start_str, end_str, args.days)
    
    # Write output
    if args.output:
        with open(args.output, 'w') as f:
            f.write(output)
        if not args.quiet:
            print(f"Leaderboard written to {args.output}", file=sys.stderr)
    else:
        print(output)
    
    return 0


def _format_leaderboard_text(leaderboard: List[Dict], start_str: str, end_str: str, days: int) -> str:
    """Format leaderboard as plain text."""
    lines = []
    lines.append("")
    lines.append("=" * 78)
    lines.append(f"  Efficiency Leaderboard | {start_str} to {end_str} ({days} days)")
    lines.append("=" * 78)
    lines.append("")
    lines.append(f"{'Rank':<6} {'User':<15} {'Jobs':>6} {'CPU Eff':>9} {'Mem Eff':>9} {'Score':>8} {'Waste Hrs':>11}")
    lines.append("-" * 78)
    
    for rank, entry in enumerate(leaderboard, 1):
        # Add medal emoji for top 3
        if rank == 1:
            rank_str = "\U0001F947 1"  # gold medal
        elif rank == 2:
            rank_str = "\U0001F948 2"  # silver medal
        elif rank == 3:
            rank_str = "\U0001F949 3"  # bronze medal
        else:
            rank_str = f"   {rank}"
        
        lines.append(
            f"{rank_str:<6} {entry['user']:<15} {entry['jobs']:>6} "
            f"{entry['avg_cpu_eff']:>8.1f}% {entry['avg_mem_eff']:>8.1f}% "
            f"{entry['combined_score']:>7.1f}% {entry['cpu_waste']:>10.1f}"
        )
    
    lines.append("")
    lines.append("Score = 60% CPU efficiency + 40% memory efficiency")
    lines.append(f"Total users: {len(leaderboard)}")
    lines.append("")
    
    return "\n".join(lines)


def _format_leaderboard_html(leaderboard: List[Dict], start_str: str, end_str: str, days: int) -> str:
    """Format leaderboard as HTML."""
    html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Efficiency Leaderboard</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1000px; margin: 0 auto; }}
        h1 {{ color: #333; border-bottom: 2px solid #007bff; padding-bottom: 10px; }}
        .subtitle {{ color: #666; margin-bottom: 20px; }}
        table {{ width: 100%; border-collapse: collapse; background: white; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border-radius: 8px; overflow: hidden; }}
        th {{ background: #007bff; color: white; padding: 12px 15px; text-align: left; font-weight: 600; }}
        td {{ padding: 10px 15px; border-bottom: 1px solid #eee; }}
        tr:hover {{ background: #f8f9fa; }}
        tr:last-child td {{ border-bottom: none; }}
        .rank {{ font-weight: bold; font-size: 1.1em; }}
        .rank-1 {{ color: #FFD700; }}
        .rank-2 {{ color: #C0C0C0; }}
        .rank-3 {{ color: #CD7F32; }}
        .medal {{ font-size: 1.3em; }}
        .score {{ font-weight: bold; color: #007bff; }}
        .waste {{ color: #dc3545; }}
        .efficiency-good {{ color: #28a745; }}
        .efficiency-warning {{ color: #ffc107; }}
        .efficiency-danger {{ color: #dc3545; }}
        .footer {{ margin-top: 20px; color: #666; font-size: 0.9em; }}
    </style>
</head>
<body>
<div class="container">
    <h1>\U0001F3C6 Efficiency Leaderboard</h1>
    <p class="subtitle">{start_str} to {end_str} ({days} days) | Score = 60% CPU + 40% Memory efficiency</p>
    
    <table>
        <thead>
            <tr>
                <th>Rank</th>
                <th>User</th>
                <th>Jobs</th>
                <th>CPU Efficiency</th>
                <th>Memory Efficiency</th>
                <th>Score</th>
                <th>CPU Hours Wasted</th>
            </tr>
        </thead>
        <tbody>
"""
    
    for rank, entry in enumerate(leaderboard, 1):
        # Medal and rank styling
        if rank == 1:
            medal = '<span class="medal">\U0001F947</span>'
            rank_class = 'rank-1'
        elif rank == 2:
            medal = '<span class="medal">\U0001F948</span>'
            rank_class = 'rank-2'
        elif rank == 3:
            medal = '<span class="medal">\U0001F949</span>'
            rank_class = 'rank-3'
        else:
            medal = ''
            rank_class = ''
        
        # Efficiency color coding
        cpu_class = 'efficiency-good' if entry['avg_cpu_eff'] >= 70 else 'efficiency-warning' if entry['avg_cpu_eff'] >= 40 else 'efficiency-danger'
        mem_class = 'efficiency-good' if entry['avg_mem_eff'] >= 60 else 'efficiency-warning' if entry['avg_mem_eff'] >= 30 else 'efficiency-danger'
        
        html += f"""            <tr>
                <td class="rank {rank_class}">{medal} {rank}</td>
                <td>{entry['user']}</td>
                <td>{entry['jobs']}</td>
                <td class="{cpu_class}">{entry['avg_cpu_eff']:.1f}%</td>
                <td class="{mem_class}">{entry['avg_mem_eff']:.1f}%</td>
                <td class="score">{entry['combined_score']:.1f}%</td>
                <td class="waste">{entry['cpu_waste']:,.1f}</td>
            </tr>
"""
    
    html += f"""        </tbody>
    </table>
    
    <p class="footer">Total users: {len(leaderboard)}</p>
</div>
</body>
</html>
"""
    return html


def cmd_report(args: argparse.Namespace) -> int:
    """Generate efficiency report for a time period."""
    config = load_config(args.config)
    
    # Calculate date range
    end_date = datetime.now()
    if args.end:
        try:
            end_date = datetime.strptime(args.end, "%Y-%m-%d")
        except ValueError:
            print(f"Error: Invalid end date format. Use YYYY-MM-DD", file=sys.stderr)
            return 1
    
    if args.start:
        try:
            start_date = datetime.strptime(args.start, "%Y-%m-%d")
        except ValueError:
            print(f"Error: Invalid start date format. Use YYYY-MM-DD", file=sys.stderr)
            return 1
    else:
        start_date = end_date - timedelta(days=args.days)
    
    start_str = start_date.strftime("%Y-%m-%d")
    end_str = end_date.strftime("%Y-%m-%d")
    
    # Build title
    title_parts = ["Job Efficiency Report"]
    if args.user:
        title_parts.append(f"User: {args.user}")
    if args.account:
        title_parts.append(f"Account: {args.account}")
    if args.partition:
        title_parts.append(f"Partition: {args.partition}")
    title_parts.append(f"{start_str} to {end_str}")
    title = " | ".join(title_parts)
    
    # Query jobs
    if not args.quiet:
        print(f"Querying jobs from {start_str} to {end_str}...", file=sys.stderr)
    
    jobs = _query_jobs_for_report(
        config,
        start_str,
        end_str,
        user=args.user,
        account=args.account,
        partition=args.partition,
    )
    
    if not jobs:
        print("No jobs found in the specified time period.", file=sys.stderr)
        return 1
    
    if not args.quiet:
        print(f"Found {len(jobs)} jobs. Calculating statistics...", file=sys.stderr)
    
    # Calculate stats
    stats = _calculate_report_stats(jobs, config)
    
    # Format output
    if args.format == 'json':
        output = _format_report_json(stats)
    elif args.format == 'csv':
        output = _format_report_csv(stats, jobs, config)
    elif args.format == 'html':
        output = _format_report_html(stats, title)
    else:
        output = _format_report_text(stats, title)
    
    # Write output
    if args.output:
        with open(args.output, 'w') as f:
            f.write(output)
        if not args.quiet:
            print(f"Report written to {args.output}", file=sys.stderr)
    else:
        print(output)
    
    return 0


def cmd_status(args: argparse.Namespace) -> int:
    """Show efficiency status of a job."""
    config = load_config(args.config)
    job_stats = JobStats(config)
    metrics = job_stats.get_job_stats(args.job_id)

    if metrics is None:
        print(f"Error: Could not get status for job {args.job_id}", file=sys.stderr)
        return 1

    print(f"\n{'='*50}")
    print(f"Job {metrics.job_id}: {metrics.job_name or 'N/A'}")
    print(f"{'='*50}")
    print(f"User:       {metrics.user}")
    print(f"State:      {metrics.state.value}")
    print(f"Partition:  {metrics.partition}")

    print(f"\n--- Resources ---")
    print(f"Nodes:      {metrics.num_nodes}")
    print(f"CPUs:       {metrics.num_cpus}")
    if metrics.has_gpus:
        print(f"GPUs:       {metrics.num_gpus}")
    print(f"Memory:     {metrics.memory_requested_gb:.1f} GB requested")

    print(f"\n--- Efficiency ---")
    cpu_bar = _make_bar(metrics.cpu_efficiency)
    mem_bar = _make_bar(metrics.memory_efficiency)
    print(f"CPU:        {cpu_bar} {metrics.cpu_efficiency:5.1f}%")
    print(f"Memory:     {mem_bar} {metrics.memory_efficiency:5.1f}% (peak: {metrics.memory_used_max_gb:.1f} GB)")
    if metrics.has_gpus:
        gpu_bar = _make_bar(metrics.gpu_utilization_avg)
        print(f"GPU:        {gpu_bar} {metrics.gpu_utilization_avg:5.1f}%")

    print(f"\n--- Time ---")
    elapsed = str(metrics.elapsed_time).split('.')[0]
    limit = str(metrics.time_limit).split('.')[0]
    time_bar = _make_bar(metrics.time_efficiency)
    print(f"Elapsed:    {elapsed}")
    print(f"Limit:      {limit}")
    print(f"Used:       {time_bar} {metrics.time_efficiency:5.1f}%")

    recommendations = _get_recommendations(metrics, config)
    if recommendations:
        print(f"\n--- Recommendations ---")
        for rec in recommendations:
            print(f"  ‚Ä¢ {rec}")

    print()

    if args.json:
        data = {
            'job_id': metrics.job_id,
            'job_name': metrics.job_name,
            'user': metrics.user,
            'state': metrics.state.value,
            'partition': metrics.partition,
            'num_nodes': metrics.num_nodes,
            'num_cpus': metrics.num_cpus,
            'num_gpus': metrics.num_gpus,
            'memory_requested_gb': metrics.memory_requested_gb,
            'memory_used_max_gb': metrics.memory_used_max_gb,
            'cpu_efficiency': metrics.cpu_efficiency,
            'memory_efficiency': metrics.memory_efficiency,
            'gpu_utilization': metrics.gpu_utilization_avg if metrics.has_gpus else None,
            'elapsed_seconds': metrics.elapsed_seconds,
            'time_limit_seconds': metrics.time_limit_seconds,
            'time_efficiency': metrics.time_efficiency,
        }
        print("JSON:")
        print(json.dumps(data, indent=2))

    return 0


def cmd_update(args: argparse.Namespace) -> int:
    """Update OOD session card for a job."""
    config = load_config(args.config)
    job_stats = JobStats(config)
    card_updater = SessionCardUpdater(config)
    metrics = job_stats.get_job_stats(args.job_id)

    if metrics is None:
        print(f"Error: Could not get metrics for job {args.job_id}", file=sys.stderr)
        return 1

    if args.session_path:
        session_path = Path(args.session_path)
    else:
        user = args.user or metrics.user
        session_path = card_updater.find_session_for_job(user, args.job_id)
        if session_path is None:
            print(f"Error: Could not find OOD session for job {args.job_id}", file=sys.stderr)
            print("Use --session-path to specify the session directory", file=sys.stderr)
            return 1

    success = card_updater.update_session_card(session_path, metrics)
    if success:
        print(f"Updated session card: {session_path / 'info.html'}")
        return 0
    else:
        print("Error: Failed to update session card", file=sys.stderr)
        return 1


def cmd_list(args: argparse.Namespace) -> int:
    """List active OOD sessions."""
    config = load_config(args.config)
    card_updater = SessionCardUpdater(config)
    job_stats = JobStats(config)
    username = args.user or pwd.getpwuid(os.getuid()).pw_name
    sessions = card_updater.list_active_sessions(username)

    if not sessions:
        print(f"No active OOD sessions found for user {username}")
        return 0

    print(f"\nActive Sessions for {username}")
    print(f"{'Job ID':<12} {'State':<12} {'CPU %':<8} {'Mem %':<8} {'Session'}")
    print("-" * 60)

    for session_path, job_id in sessions:
        metrics = job_stats.get_job_stats(job_id)
        if metrics:
            state = metrics.state.value[:10]
            cpu = f"{metrics.cpu_efficiency:.1f}" if metrics.cpu_efficiency > 0 else "-"
            mem = f"{metrics.memory_efficiency:.1f}" if metrics.memory_efficiency > 0 else "-"
        else:
            state = "UNKNOWN"
            cpu = "-"
            mem = "-"
        print(f"{job_id:<12} {state:<12} {cpu:<8} {mem:<8} {session_path.name}")

    print()
    return 0


def cmd_html(args: argparse.Namespace) -> int:
    """Generate HTML card for a job."""
    config = load_config(args.config)
    job_stats = JobStats(config)
    card_updater = SessionCardUpdater(config)
    metrics = job_stats.get_job_stats(args.job_id)

    if metrics is None:
        print(f"Error: Could not get metrics for job {args.job_id}", file=sys.stderr)
        return 1

    html = card_updater.generate_card_html(metrics)
    if args.output:
        with open(args.output, 'w') as f:
            f.write(html)
        print(f"HTML written to {args.output}")
    else:
        print(html)

    return 0


def create_parser() -> argparse.ArgumentParser:
    """Create the argument parser."""
    parser = argparse.ArgumentParser(
        prog='schmutz',
        description='Display Slurm job efficiency metrics (like jobstats/jobperf)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  schmutz 12345                        Show efficiency for job 12345
  schmutz status 12345                 Same as above
  schmutz update 12345                 Update OOD session card for job
  schmutz list                         List active OOD sessions
  schmutz html 12345                   Output HTML card to stdout

  schmutz report                       Weekly report for current user
  schmutz report --days 7              Last 7 days (default)
  schmutz report --user jsmith         Report for specific user
  schmutz report --account physics     Report for account/group
  schmutz report --format html -o r.html  Generate HTML report
  schmutz report --start 2026-01-01 --end 2026-01-31  Custom date range

  schmutz leaderboard                  Rank all users by efficiency (7 days)
  schmutz leaderboard --days 30        Last 30 days
  schmutz leaderboard --sort waste     Rank by CPU hours wasted
  schmutz leaderboard --min-jobs 5     Only users with 5+ jobs
"""
    )

    parser.add_argument('--version', '-V', action='version', version=f'%(prog)s {__version__}')
    parser.add_argument('--config', '-c', help='Path to configuration file')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose output')
    parser.add_argument('--debug', action='store_true', help='Enable debug output')
    parser.add_argument('--json', '-j', action='store_true', help='Output JSON')

    subparsers = parser.add_subparsers(dest='command', help='Commands')

    status_parser = subparsers.add_parser('status', help='Show job efficiency status')
    status_parser.add_argument('job_id', help='Slurm job ID')
    status_parser.add_argument('--json', '-j', action='store_true', help='Output JSON')
    status_parser.set_defaults(func=cmd_status)

    update_parser = subparsers.add_parser('update', help='Update OOD session card')
    update_parser.add_argument('job_id', help='Slurm job ID')
    update_parser.add_argument('--session-path', '-s', help='Path to OOD session directory')
    update_parser.add_argument('--user', '-u', help='Username for finding session')
    update_parser.set_defaults(func=cmd_update)

    list_parser = subparsers.add_parser('list', help='List active OOD sessions')
    list_parser.add_argument('--user', '-u', help='User to list sessions for')
    list_parser.set_defaults(func=cmd_list)

    html_parser = subparsers.add_parser('html', help='Generate HTML card')
    html_parser.add_argument('job_id', help='Slurm job ID')
    html_parser.add_argument('--output', '-o', help='Output file (default: stdout)')
    html_parser.set_defaults(func=cmd_html)

    # Report subcommand
    report_parser = subparsers.add_parser('report', help='Generate efficiency report')
    report_parser.add_argument('--days', '-d', type=int, default=7,
                               help='Number of days to include (default: 7)')
    report_parser.add_argument('--start', help='Start date (YYYY-MM-DD)')
    report_parser.add_argument('--end', help='End date (YYYY-MM-DD, default: today)')
    report_parser.add_argument('--user', '-u', help='Filter by username')
    report_parser.add_argument('--account', '-a', help='Filter by Slurm account')
    report_parser.add_argument('--partition', '-p', help='Filter by partition')
    report_parser.add_argument('--format', '-f', choices=['text', 'json', 'csv', 'html'],
                               default='text', help='Output format (default: text)')
    report_parser.add_argument('--output', '-o', help='Output file (default: stdout)')
    report_parser.add_argument('--quiet', '-q', action='store_true',
                               help='Suppress progress messages')
    report_parser.set_defaults(func=cmd_report)

    # Leaderboard subcommand
    lb_parser = subparsers.add_parser('leaderboard', help='Rank users by efficiency')
    lb_parser.add_argument('--days', '-d', type=int, default=7,
                           help='Number of days to include (default: 7)')
    lb_parser.add_argument('--account', '-a', help='Filter by Slurm account')
    lb_parser.add_argument('--partition', '-p', help='Filter by partition')
    lb_parser.add_argument('--sort', '-s', choices=['efficiency', 'cpu', 'memory', 'jobs', 'waste'],
                           default='efficiency', help='Sort by (default: efficiency)')
    lb_parser.add_argument('--top', '-t', type=int, help='Show only top N users')
    lb_parser.add_argument('--min-jobs', '-m', type=int, default=0,
                           help='Minimum jobs to be included (default: 0)')
    lb_parser.add_argument('--format', '-f', choices=['text', 'json', 'html'],
                           default='text', help='Output format (default: text)')
    lb_parser.add_argument('--output', '-o', help='Output file (default: stdout)')
    lb_parser.add_argument('--quiet', '-q', action='store_true',
                           help='Suppress progress messages')
    lb_parser.set_defaults(func=cmd_leaderboard)

    return parser


def main() -> int:
    """Main entry point."""
    # Check if first non-flag argument looks like a job ID (numeric)
    # This allows "schmutz 12345" as shorthand for "schmutz status 12345"
    argv = sys.argv[1:]
    
    # Find first positional argument (skip flags)
    i = 0
    while i < len(argv):
        arg = argv[i]
        if arg.startswith('-'):
            # Skip flag and its value if it takes one
            if arg in ('-c', '--config', '-o', '--output', '-s', '--session-path', '-u', '--user'):
                i += 2
            else:
                i += 1
        else:
            # Found positional argument
            if arg.isdigit() or (arg.replace('_', '').isdigit()):
                # Looks like a job ID, insert 'status' command
                argv.insert(i, 'status')
            break
    
    parser = create_parser()
    args = parser.parse_args(argv)

    setup_logging(verbose=args.verbose, debug=args.debug)

    if args.command is None:
        parser.print_help()
        return 0

    # Verify job_id for commands that require it
    if args.command in ('status', 'update', 'html'):
        if not hasattr(args, 'job_id') or not args.job_id:
            print(f"Error: job_id is required for '{args.command}' command", file=sys.stderr)
            return 1

    return args.func(args)


if __name__ == '__main__':
    sys.exit(main())
